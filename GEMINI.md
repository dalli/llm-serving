# GEMINI.md - Detailed Development Plan for AI Model Serving Engine

## 1. ğŸ¯ Project Overview

This document is a detailed development plan and execution guide for successfully carrying out the AI Model Serving Engine project based on the requirements specified in `prd.md`.

- **Vision**: To implement a unified AI serving platform that efficiently serves LLM, multimodal, and embedding models in a local environment.
- **Mission**: To build a production-grade serving engine that provides OpenAI API compatibility, supports various AI models, and ensures high performance and stability.

## 2. ğŸ—ï¸ Architecture & Tech Stack

### 2.1 Architectural Blueprint

```mermaid
graph TB
    subgraph "AI Model Serving Engine"
        direction LR
        
        subgraph "API Layer"
            Router[API Router - Axum]
        end

        subgraph "Core Logic"
            Engine[Core Engine]
            Scheduler[Request Scheduler]
            Cache[Response Cache]
        end
        
        subgraph "Runtime Layer"
            LLM_Runtime[LLM Runtime]
            Multimodal_Runtime[Multimodal Runtime]
            Embedding_Runtime[Embedding Runtime]
            Image_Runtime[Image Gen Runtime]
        end

        subgraph "Management"
            Monitor[Resource Monitor]
            Admin[Admin APIs]
        end
    end

    Router --> Scheduler
    Scheduler --> Engine
    Engine --> LLM_Runtime
    Engine --> Multimodal_Runtime
    Engine --> Embedding_Runtime
    Engine --> Image_Runtime
    Engine --> Cache
    Admin --> Engine
    Monitor --> Engine
```

### 2.2 Tech Stack

| Layer | Technology | Version | Reason |
|---|---|---|---|
| **Language** | Rust | 1.75+ | Performance, memory safety |
| **Web Framework** | Axum | 0.7+ | Async, type safety |
| **Async Runtime** | Tokio | 1.35+ | High-performance async processing |
| **Model Runtime** | llama.cpp, ONNX, PyTorch | latest | Support for various model formats |
| **Serialization** | Serde | 1.0+ | JSON processing |
| **Logging** | tracing | 0.1+ | Structured logging |
| **Metrics** | Prometheus | 0.13+ | Monitoring |
| **Caching** | moka | 0.12+ | High-performance cache |

## 3. ğŸ›£ï¸ Detailed Development Roadmap & Action Plan

Based on the roadmap in `prd.md`, we define specific action items for each phase.

### Phase 1: Text LLM MVP (4 weeks)
- **Goal**: Implement basic text LLM serving functionality compatible with the OpenAI Chat API.
- **Detailed Tasks**:
    - [x] **Initial Project Setup**
        - [x] Create project structure using `cargo` (`main.rs`, `api`, `engine`, `runtime` modules)
        - [x] Add core dependencies to `Cargo.toml` (axum, tokio, serde, tracing, llama-cpp-rs)
    - [x] **F1: Implement Chat API**
        - [x] Define OpenAI Chat API request/response DTOs using `serde` (PRD 5.3.1, 5.3.4)
        - [x] Implement the `/v1/chat/completions` route and handler using `axum`
        - [x] Implement `text/event-stream` handling logic for streaming responses
        - [x] Define and implement standard API error response formats
    - [x] **F2: Text Model Runtime**
        - [x] Define an `LlmRuntime` Trait for abstraction
        - [x] Implement `LlamaCppRuntime` using `llama.cpp` Rust bindings
        - [x] Implement GGUF/GGML model file loading and memory mapping
        - [x] Implement text generation logic for input prompts
    - [x] **F3: Core Engine & Concurrency**
        - [x] Define the `CoreEngine` struct for managing model runtimes
        - [x] Implement a request queue using `tokio::mpsc` channel
        - [x] Implement a Tokio task worker pool to process requests concurrently
        - [x] Integrate the API handler with the core engine

### Phase 2: Multimodal Support (4 weeks)
- **Goal**: Add support for embedding and vision-language models.
- **Detailed Tasks**:
    - [x] **F1: Implement Embeddings API**
        - [x] Define Embeddings API DTOs using `serde` (PRD 5.3.2)
        - [x] Implement the `/v1/embeddings` route and handler using `axum`
    - [ ] **F2: Embedding Model Runtime**
        - [x] Define an `EmbeddingRuntime` Trait
        - [ ] Implement inference logic for Sentence Transformers series models using ONNX runtime (ort)
        - [x] Integrate the embedding runtime into the `CoreEngine`
        - [x] Add ONNX runtime scaffolding behind `onnx` feature and env-based auto-load
    - [x] **F1/F2: Vision-Language Model Support**
        - [x] Extend Chat API DTOs to support vision inputs
        - [x] Define a `MultimodalRuntime` Trait and dummy implementation
        - [ ] Support LLaVA model architecture (CLIP Vision Encoder + LLM)
        - [x] Integrate the multimodal runtime into the `CoreEngine` and add routing logic

### Phase 3: Stabilization & Management (3 weeks)
- **Goal**: Ensure stability and management features for production operation.
- **Detailed Tasks**:
    - [x] **F4: Response Caching**
        - [x] Add `moka` dependency and initialize the cache instance
        - [x] Add LRU caching logic within the `CoreEngine` (using request hash as key)
        - [x] Implement cache TTL (Time-To-Live) configuration
    - [x] **F5: Dynamic Model Management**
        - [x] Implement `POST /admin/models/load` and `POST /admin/models/unload` API endpoints
        - [x] Modify the `CoreEngine` to dynamically load/unload models without service interruption (e.g., using `Arc<Mutex<HashMap>>`)
        - [x] Implement functionality to view the list and status of currently loaded models via `GET /admin/models`
    - [x] **F6: Service Monitoring**
        - [x] Add `metrics` and `metrics-exporter-prometheus` dependencies
        - [x] Add code to collect key metrics (request count, latency, cache hit/store/miss)
        - [x] Implement the `/admin/metrics` endpoint
        - [x] Implement the `/health` health check endpoint

### Phase 4: Image Generation & Enhancements (5 weeks)
- **Goal**: Implement support for image generation models and advanced features.
- **Detailed Tasks**:
    - [ ] **F1: Implement Image Generation API**
        - [ ] Define Image Generation API DTOs using `serde` (PRD 5.3.3)
        - [ ] Implement the `/v1/images/generations` route and handler using `axum`
    - [ ] **F2: Image Generation Runtime**
        - [ ] Define an `ImageGenRuntime` Trait
        - [ ] Implement inference logic for Stable Diffusion models (using ONNX or PyTorch bindings)
        - [ ] Integrate the image generation runtime into the `CoreEngine`
    - [ ] **F8: Multi-Type Model Concurrent Serving**
        - [ ] Refactor the `CoreEngine` to manage various types of models concurrently (LLM, Embedding, Multimodal, Image Gen)
        - [ ] Implement logic to route requests to the appropriate runtime based on the `model` field in the API request
    - [ ] **F9: Authentication & Authorization**
        - [ ] Implement Bearer Token authentication logic using `axum` middleware
        - [ ] Implement per-API key Rate Limiting logic (using the `governor` crate)

### Phase 5: Decentralization (6 weeks)
- **Goal**: Support scalability in a distributed environment based on Kubernetes.
- **Detailed Tasks**:
    - [ ] **F10: Containerization**
        - [ ] Create a lightweight production Docker image using a multi-stage build
        - [ ] Include the NVIDIA CUDA runtime in the Docker image for GPU support
    - [ ] **F10: Kubernetes Deployment**
        - [ ] Create a deployment chart using `Helm` (Deployment, Service, ConfigMap, Secret)
        - [ ] Configure Liveness/Readiness Probes using the `/health` endpoint
        - [ ] Set up resource requests and limits for the HPA (Horizontal Pod Autoscaler)
        - [ ] Configure `deployment.yaml` to request and use GPU resources

## 4. âš™ï¸ Development Process & Principles

### 4.1 Test-Driven Development (TDD)

- All feature development will follow the **Test-Driven Development (TDD)** methodology.
- We will adhere to the **`Red-Green-Refactor`** cycle: first write a failing test, then write the code to pass the test, and finally refactor the code.
- All API endpoints, core logic, and utility functions must be verified with unit tests (`cargo test`) and integration tests. As specified in the PRD, we aim for a **test coverage of over 80%**.

### 4.2 Version Control & History

- **Git Commit Strategy**: Upon completion of each phase, all changes for that phase will be committed as a single atomic unit. The commit message will follow the format `feat(phase-X): [Phase Name]` (e.g., `feat(phase-1): Complete Text LLM MVP`).
- **Work History Management**: At the end of each phase, a `history.md` file will be created and updated with the work history in the following format. This is to track project progress, share knowledge, and facilitate continuous improvement.

```markdown
# Work History

## Phase X: [Phase Name]

- **Duration:** YYYY-MM-DD ~ YYYY-MM-DD
- **Completed Work:**
  - [List of detailed tasks for the Phase as defined in GEMINI.md]
- **Issues Encountered:**
  - **Issue 1:** [Specific description of the problem]
  - **Cause:** [Analysis of the root cause of the problem]
  - **Solution:** [Methods attempted to solve the problem and the final solution]
- **Retrospective:**
  - **What went well:** [Positive aspects of the process, technology choices, collaboration, etc.]
  - **What to improve:** [Areas for improvement in the next Phase]
```

## 5. ğŸ“ References & Notes

- This development plan is based on the `prd.md` document.
- The content of `plan.md` was not provided. This document will be further updated to refine the plan once its content is shared.
- Tests for each stage (unit, integration, performance) will be conducted in parallel.


## 1. ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš” (Project Overview)

ì´ ë¬¸ì„œëŠ” `prd.md`ì— ëª…ì‹œëœ ìš”êµ¬ì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ AI Model Serving Engine í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ìƒì„¸ ê°œë°œ ê³„íš ë° ì‹¤í–‰ ê°€ì´ë“œì…ë‹ˆë‹¤.

- **ë¹„ì „ (Vision)**: ë¡œì»¬ í™˜ê²½ì—ì„œ LLM, ë©€í‹°ëª¨ë‹¬, ì„ë² ë”© ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì„œë¹™í•˜ëŠ” í†µí•© AI ì„œë¹™ í”Œë«í¼ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
- **ë¯¸ì…˜ (Mission)**: OpenAI APIì™€ í˜¸í™˜ì„±ì„ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ AI ëª¨ë¸ì„ ì§€ì›í•˜ê³ , ë†’ì€ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ë³´ì¥í•˜ëŠ” í”„ë¡œë•ì…˜ê¸‰ ì„œë¹™ ì—”ì§„ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

## 2. ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë° ê¸°ìˆ  ìŠ¤íƒ (Architecture & Tech Stack)

### 2.1 ì•„í‚¤í…ì²˜ ì²­ì‚¬ì§„ (Architectural Blueprint)

```mermaid
graph TB
    subgraph "AI Model Serving Engine"
        direction LR
        
        subgraph "API Layer"
            Router[API Router - Axum]
        end

        subgraph "Core Logic"
            Engine[Core Engine]
            Scheduler[Request Scheduler]
            Cache[Response Cache]
        end
        
        subgraph "Runtime Layer"
            LLM_Runtime[LLM Runtime]
            Multimodal_Runtime[Multimodal Runtime]
            Embedding_Runtime[Embedding Runtime]
            Image_Runtime[Image Gen Runtime]
        end

        subgraph "Management"
            Monitor[Resource Monitor]
            Admin[Admin APIs]
        end
    end

    Router --> Scheduler
    Scheduler --> Engine
    Engine --> LLM_Runtime
    Engine --> Multimodal_Runtime
    Engine --> Embedding_Runtime
    Engine --> Image_Runtime
    Engine --> Cache
    Admin --> Engine
    Monitor --> Engine
```

### 4.3 Task Lifecycle Rule (per-task)

- For every task derived from this document:
  - Complete development and ensure tests pass: `cargo test`.
  - Update `history.md` with:
    - Completed work (concise bullets)
    - Issues encountered
    - Root cause and solution
    - Retrospective (what went well, what to improve)
  - Commit with a message starting with `feat(phase-X):`, `fix(phase-X):`, or `chore(phase-X):` as appropriate.
  - Push to `origin`.
  - Optional helper: use `scripts/finish_task.sh` to append a standardized entry.

### 2.2 ê¸°ìˆ  ìŠ¤íƒ (Tech Stack)

| ê³„ì¸µ | ê¸°ìˆ  | ë²„ì „ | ì´ìœ  |
|------|------|------|------|
| **ì–¸ì–´** | Rust | 1.75+ | ì„±ëŠ¥, ë©”ëª¨ë¦¬ ì•ˆì „ì„± |
| **ì›¹ í”„ë ˆì„ì›Œí¬** | Axum | 0.7+ | ë¹„ë™ê¸°, íƒ€ì… ì•ˆì „ì„± |
| **ë¹„ë™ê¸° ëŸ°íƒ€ì„** | Tokio | 1.35+ | ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì²˜ë¦¬ |
| **ëª¨ë¸ ëŸ°íƒ€ì„** | llama.cpp, ONNX, PyTorch | latest | ë‹¤ì–‘í•œ ëª¨ë¸ í˜•ì‹ ì§€ì› |
| **ì§ë ¬í™”** | Serde | 1.0+ | JSON ì²˜ë¦¬ |
| **ë¡œê¹…** | tracing | 0.1+ | êµ¬ì¡°í™” ë¡œê¹… |
| **ë©”íŠ¸ë¦­** | Prometheus | 0.13+ | ëª¨ë‹ˆí„°ë§ |
| **ìºì‹±** | moka | 0.12+ | ê³ ì„±ëŠ¥ ìºì‹œ |

## 3. ğŸ›£ï¸ ìƒì„¸ ê°œë°œ ë¡œë“œë§µ ë° ì‹¤í–‰ ê³„íš (Detailed Development Roadmap & Action Plan)

`prd.md`ì˜ ë¡œë“œë§µì„ ê¸°ë°˜ìœ¼ë¡œ ê° ë‹¨ê³„ë³„ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³¼ì œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

### Phase 1: í…ìŠ¤íŠ¸ LLM MVP (4ì£¼)
- **ëª©í‘œ**: OpenAI Chat APIì™€ í˜¸í™˜ë˜ëŠ” ê¸°ë³¸ í…ìŠ¤íŠ¸ LLM ì„œë¹™ ê¸°ëŠ¥ êµ¬í˜„.
- **ì„¸ë¶€ ê³¼ì œ**:
    - [x] **í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì •**
        - [x] `cargo`ë¥¼ ì´ìš©í•œ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„± (`main.rs`, `api`, `engine`, `runtime` ëª¨ë“ˆ)
        - [x] `Cargo.toml`ì— í•µì‹¬ ì˜ì¡´ì„± ì¶”ê°€ (axum, tokio, serde, tracing, llama-cpp-rs)
    - [x] **F1: Chat API êµ¬í˜„**
        - [x] `serde`ë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI Chat API ìš”ì²­/ì‘ë‹µ DTO ì •ì˜ (PRD 5.3.1, 5.3.4)
        - [x] `axum`ì„ ì‚¬ìš©í•˜ì—¬ `/v1/chat/completions` ë¼ìš°íŠ¸ ë° í•¸ë“¤ëŸ¬ êµ¬í˜„
        - [x] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ `text/event-stream` ì²˜ë¦¬ ë¡œì§ êµ¬í˜„
        - [x] í‘œì¤€ API ì—ëŸ¬ ì‘ë‹µ í˜•ì‹ ì •ì˜ ë° êµ¬í˜„
    - [ ] **F2: í…ìŠ¤íŠ¸ ëª¨ë¸ ëŸ°íƒ€ì„**
        - [x] `LlmRuntime` Trait ì •ì˜ (ì¶”ìƒí™”)
        - [ ] `llama.cpp` Rust ë°”ì¸ë”©ì„ ì‚¬ìš©í•œ `LlamaCppRuntime` êµ¬í˜„
        - [ ] GGUF/GGML ëª¨ë¸ íŒŒì¼ ë¡œë”© ë° ë©”ëª¨ë¦¬ ë§¤í•‘ ê¸°ëŠ¥ êµ¬í˜„
        - [x] ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ìƒì„± ë¡œì§ êµ¬í˜„
    - [ ] **F3: ì½”ì–´ ì—”ì§„ ë° ë™ì‹œì„± ì²˜ë¦¬**
        - [x] `CoreEngine` êµ¬ì¡°ì²´ ì •ì˜ (ëª¨ë¸ ëŸ°íƒ€ì„ ê´€ë¦¬)
        - [x] `tokio::mpsc` ì±„ë„ì„ ì‚¬ìš©í•œ ìš”ì²­ í(Queue) êµ¬í˜„
        - [ ] ì—¬ëŸ¬ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ê¸° ìœ„í•œ Tokio íƒœìŠ¤í¬ ì›Œì»¤ í’€(Worker Pool) êµ¬í˜„
        - [x] API í•¸ë“¤ëŸ¬ì™€ ì½”ì–´ ì—”ì§„ ì—°ë™

### Phase 2: ë©€í‹°ëª¨ë‹¬ ì§€ì› (4ì£¼)
- **ëª©í‘œ**: ì„ë² ë”© ë° ë¹„ì „-ì–¸ì–´ ëª¨ë¸ ì§€ì› ì¶”ê°€.
- **ì„¸ë¶€ ê³¼ì œ**:
    - [ ] **F1: Embeddings API êµ¬í˜„**
        - [ ] `serde`ë¥¼ ì‚¬ìš©í•˜ì—¬ Embeddings API DTO ì •ì˜ (PRD 5.3.2)
        - [ ] `axum`ì„ ì‚¬ìš©í•˜ì—¬ `/v1/embeddings` ë¼ìš°íŠ¸ ë° í•¸ë“¤ëŸ¬ êµ¬í˜„
    - [ ] **F2: ì„ë² ë”© ëª¨ë¸ ëŸ°íƒ€ì„**
        - [ ] `EmbeddingRuntime` Trait ì •ì˜
        - [ ] ONNX ëŸ°íƒ€ì„(ort)ì„ ì‚¬ìš©í•˜ì—¬ Sentence Transformers ê³„ì—´ ëª¨ë¸ ì¶”ë¡  ë¡œì§ êµ¬í˜„
        - [ ] `CoreEngine`ì— ì„ë² ë”© ëŸ°íƒ€ì„ í†µí•©
    - [ ] **F1/F2: Vision-Language ëª¨ë¸ ì§€ì›**
        - [ ] Chat API DTOë¥¼ í™•ì¥í•˜ì—¬ `image_url` ì…ë ¥ ì§€ì› (PRD 5.3.1)
        - [ ] `MultimodalRuntime` Trait ì •ì˜
        - [ ] LLaVA ëª¨ë¸ ì•„í‚¤í…ì²˜ ì§€ì› (CLIP Vision Encoder + LLM)
        - [ ] `CoreEngine`ì— ë©€í‹°ëª¨ë‹¬ ëŸ°íƒ€ì„ í†µí•© ë° ë¼ìš°íŒ… ë¡œì§ ì¶”ê°€

### Phase 3: ì•ˆì •í™” ë° ê´€ë¦¬ (3ì£¼)
- **ëª©í‘œ**: í”„ë¡œë•ì…˜ ìš´ì˜ì„ ìœ„í•œ ì•ˆì •ì„± ë° ê´€ë¦¬ ê¸°ëŠ¥ í™•ë³´.
- **ì„¸ë¶€ ê³¼ì œ**:
    - [ ] **F4: ì‘ë‹µ ìºì‹±**
        - [ ] `moka` ì˜ì¡´ì„± ì¶”ê°€ ë° ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        - [ ] `CoreEngine` ë‚´ë¶€ì— LRU ìºì‹± ë¡œì§ ì¶”ê°€ (ìš”ì²­ í•´ì‹œ ê¸°ë°˜ í‚¤)
        - [ ] ìºì‹œ TTL(Time-To-Live) ì„¤ì • ê¸°ëŠ¥ êµ¬í˜„
    - [ ] **F5: ë™ì  ëª¨ë¸ ê´€ë¦¬**
        - [ ] `POST /admin/models/load`, `POST /admin/models/unload` API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
        - [ ] `CoreEngine`ì´ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ì´ ëª¨ë¸ì„ ë™ì ìœ¼ë¡œ ë¡œë“œ/ì–¸ë¡œë“œ í•˜ë„ë¡ ìˆ˜ì • (`Arc<Mutex<HashMap>>` ë“± í™œìš©)
        - [ ] `GET /admin/models`ë¥¼ í†µí•´ í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ëª©ë¡ ë° ìƒíƒœ ì¡°íšŒ ê¸°ëŠ¥ êµ¬í˜„
    - [ ] **F6: ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§**
        - [ ] `metrics` ë° `metrics-exporter-prometheus` ì˜ì¡´ì„± ì¶”ê°€
        - [ ] ì£¼ìš” ì§€í‘œ(ìš”ì²­ ìˆ˜, ì§€ì—° ì‹œê°„, ì—ëŸ¬ìœ¨, ìºì‹œ íˆíŠ¸ìœ¨) ìˆ˜ì§‘ ì½”ë“œ ì¶”ê°€
        - [ ] `/admin/metrics` ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
        - [ ] `/health` í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„

### Phase 4: ì´ë¯¸ì§€ ìƒì„± ë° ê³ ë„í™” (5ì£¼)
- **ëª©í‘œ**: ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ì§€ì› ë° ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„.
- **ì„¸ë¶€ ê³¼ì œ**:
    - [ ] **F1: Image Generation API êµ¬í˜„**
        - [ ] `serde`ë¥¼ ì‚¬ìš©í•˜ì—¬ Image Generation API DTO ì •ì˜ (PRD 5.3.3)
        - [ ] `axum`ì„ ì‚¬ìš©í•˜ì—¬ `/v1/images/generations` ë¼ìš°íŠ¸ ë° í•¸ë“¤ëŸ¬ êµ¬í˜„
    - [ ] **F2: ì´ë¯¸ì§€ ìƒì„± ëŸ°íƒ€ì„**
        - [ ] `ImageGenRuntime` Trait ì •ì˜
        - [ ] Stable Diffusion ëª¨ë¸ ì¶”ë¡  ë¡œì§ êµ¬í˜„ (ONNX ë˜ëŠ” PyTorch ë°”ì¸ë”© í™œìš©)
        - [ ] `CoreEngine`ì— ì´ë¯¸ì§€ ìƒì„± ëŸ°íƒ€ì„ í†µí•©
    - [ ] **F8: ë©€í‹°íƒ€ì… ëª¨ë¸ ë™ì‹œ ì„œë¹™**
        - [ ] `CoreEngine`ì„ ë¦¬íŒ©í† ë§í•˜ì—¬ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ëª¨ë¸(LLM, Embedding, Multimodal, Image Gen)ì„ ë™ì‹œì— ê´€ë¦¬í•˜ë„ë¡ ê°œì„ 
        - [ ] API ìš”ì²­ì˜ `model` í•„ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ëŸ°íƒ€ì„ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ë¡œì§ êµ¬í˜„
    - [ ] **F9: ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬**
        - [ ] `axum` ë¯¸ë“¤ì›¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ Bearer í† í° ì¸ì¦ ë¡œì§ êµ¬í˜„
        - [ ] API í‚¤ë³„ Rate Limiting ë¡œì§ êµ¬í˜„ (`governor` í¬ë ˆì´íŠ¸ í™œìš©)

### Phase 5: ë¶„ì‚°í™” (6ì£¼)
- **ëª©í‘œ**: Kubernetes ê¸°ë°˜ì˜ ë¶„ì‚° í™˜ê²½ì—ì„œ í™•ì¥ ê°€ëŠ¥í•˜ë„ë¡ ì§€ì›.
- **ì„¸ë¶€ ê³¼ì œ**:
    - [ ] **F10: ì»¨í…Œì´ë„ˆí™”**
        - [ ] Multi-stage buildë¥¼ í™œìš©í•˜ì—¬ í”„ë¡œë•ì…˜ìš© ê²½ëŸ‰ Docker ì´ë¯¸ì§€ ìƒì„±
        - [ ] Docker ì´ë¯¸ì§€ì— NVIDIA CUDA ëŸ°íƒ€ì„ í¬í•¨í•˜ì—¬ GPU ì§€ì›
    - [ ] **F10: Kubernetes ë°°í¬**
        - [ ] `Helm`ì„ ì‚¬ìš©í•˜ì—¬ ë°°í¬ ì°¨íŠ¸ ì‘ì„± (Deployment, Service, ConfigMap, Secret)
        - [ ] `/health` ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” Liveness/Readiness Probe ì„¤ì •
        - [ ] HPA(Horizontal Pod Autoscaler)ë¥¼ ìœ„í•œ ë¦¬ì†ŒìŠ¤ ìš”ì²­ ë° ì œí•œ ì„¤ì •
        - [ ] GPU ë¦¬ì†ŒìŠ¤ë¥¼ ìš”ì²­í•˜ê³  ì‚¬ìš©í•˜ë„ë¡ `deployment.yaml` ì„¤ì •

## 4. âš™ï¸ ê°œë°œ í”„ë¡œì„¸ìŠ¤ ë° ì›ì¹™ (Development Process & Principles)

### 4.1 í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ (Test-Driven Development - TDD)

- ëª¨ë“  ê¸°ëŠ¥ ê°œë°œì€ **í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ(TDD)** ë°©ë²•ë¡ ì„ ë”°ë¦…ë‹ˆë‹¤.
- **`Red-Green-Refactor`** ì‚¬ì´í´ì„ ì¤€ìˆ˜í•˜ì—¬, ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³ , í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•œ ë’¤, ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§í•©ë‹ˆë‹¤.
- ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸, í•µì‹¬ ë¡œì§, ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ëŠ” ë‹¨ìœ„ í…ŒìŠ¤íŠ¸(`cargo test`) ë° í†µí•© í…ŒìŠ¤íŠ¸ë¡œ ê²€ì¦ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. PRDì— ëª…ì‹œëœ ëŒ€ë¡œ **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 80% ì´ìƒ**ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### 4.2 ë²„ì „ ê´€ë¦¬ ë° íˆìŠ¤í† ë¦¬

- **Git Commit ì „ëµ**: ê° Phaseì˜ ê°œë°œì´ ì™„ë£Œë˜ë©´, í•´ë‹¹ Phaseì˜ ëª¨ë“  ë³€ê²½ì‚¬í•­ì„ í•˜ë‚˜ì˜ ì›ìì  ë‹¨ìœ„ë¡œ ì»¤ë°‹í•©ë‹ˆë‹¤. ì»¤ë°‹ ë©”ì‹œì§€ëŠ” `feat(phase-X): [Phase ì´ë¦„]` í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤. (ì˜ˆ: `feat(phase-1): Complete Text LLM MVP`)
- **ì‘ì—… ì´ë ¥ ê´€ë¦¬**: ê° Phaseê°€ ì¢…ë£Œë  ë•Œë§ˆë‹¤, `history.md` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ í˜•ì‹ì— ë”°ë¼ ì‘ì—… ë‚´ì—­ì„ ê¸°ë¡í•©ë‹ˆë‹¤. ì´ëŠ” í”„ë¡œì íŠ¸ì˜ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ê³ , ì§€ì‹ì„ ê³µìœ í•˜ë©°, ì§€ì†ì ì¸ ê°œì„ ì„ ìœ„í•¨ì…ë‹ˆë‹¤.

```markdown
# Work History

## Phase X: [Phase ì´ë¦„]

- **ì‘ì—… ê¸°ê°„ (Duration):** YYYY-MM-DD ~ YYYY-MM-DD
- **ì™„ë£Œëœ ì‘ì—… (Completed Work):**
  - [GEMINI.mdì— ì •ì˜ëœ Phaseì˜ ì„¸ë¶€ ê³¼ì œ ëª©ë¡]
- **ë°œìƒ ì´ìŠˆ (Issues Encountered):**
  - **ì´ìŠˆ 1:** [ë¬¸ì œ ìƒí™©ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¤ëª…]
  - **ì›ì¸:** [ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„]
  - **í•´ê²° ë°©ì•ˆ:** [ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹œë„í•œ ë°©ë²• ë° ìµœì¢… í•´ê²°ì±…]
- **íšŒê³  (Retrospective):**
  - **ì˜í•œ ì  (What went well):** [í”„ë¡œì„¸ìŠ¤, ê¸°ìˆ  ì„ íƒ, í˜‘ì—… ë“±ì—ì„œ ê¸ì •ì ì´ì—ˆë˜ ë¶€ë¶„]
  - **ê°œì„ í•  ì  (What to improve):** [ë‹¤ìŒ Phaseì—ì„œ ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„]
```

## 5. ğŸ“ ì°¸ê³  ë° Ù…Ù„Ø§Ø­Ø¸Ø§Øª (References & Notes)

- ì´ ê°œë°œ ê³„íšì€ `prd.md` ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
- `plan.md` íŒŒì¼ì˜ ë‚´ìš©ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ì˜ ë‚´ìš©ì´ ê³µìœ ë˜ë©´ ì´ ë¬¸ì„œë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ ê³„íšì„ êµ¬ì²´í™”í•  ì˜ˆì •ì…ë‹ˆë‹¤.
- ê° ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸(ë‹¨ìœ„, í†µí•©, ì„±ëŠ¥)ëŠ” ë³‘í–‰í•˜ì—¬ ì§„í–‰í•©ë‹ˆë‹¤.