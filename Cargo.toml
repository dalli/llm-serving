[package]
name = "llm-serving"
version = "0.1.0"
edition = "2024"

[dependencies]
axum = { version = "0.7", features = ["macros"] }
tokio = { version = "1.35", features = ["full", "sync"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tracing = "0.1"
llama_cpp = { version = "0.3.2", optional = true }
uuid = { version = "1.0", features = ["v4"] }
tokio-stream = "0.1"
async-trait = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt"] }
futures = "0.3"
tower = "0.5"
moka = { version = "0.12", features = ["future"] }
sha2 = "0.10"
memmap2 = "0.9"
rand = "0.8"
metrics = "0.21"
metrics-exporter-prometheus = "0.14"

[features]
default = []
llama = ["dep:llama_cpp"]

