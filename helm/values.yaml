image:
  repository: ghcr.io/your-org/llm-serving
  tag: latest
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 3000

resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi

env: {}

hcmSecret:
  enabled: false
  name: llm-serving-secret
  data:
    # Example: API_KEYS: "key1,key2"
    API_KEYS: ""

hpa:
  enabled: false
  minReplicas: 1
  maxReplicas: 3
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70

# Example GPU configuration (uncomment and set as needed)
gpu:
  enabled: false
  count: 1
